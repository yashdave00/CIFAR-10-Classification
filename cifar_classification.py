# -*- coding: utf-8 -*-
"""cifar_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12zz5JWLEeeD6lCXiCcPWXYNT3xXldwPZ
"""

from matplotlib import pyplot
from keras.datasets import cifar10
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D,Activation,BatchNormalization
from tensorflow.keras.losses import SparseCategoricalCrossentropy
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.utils import to_categorical
import os
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs

"""**Import Statements**

**Exploring the data a little bit**
"""

def explore_data():
  (trainX, trainy), (testX, testy) = cifar10.load_data()
# summarize loaded dataset
  print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))
  print('Test: X=%s, y=%s' % (testX.shape, testy.shape))
  # plot first few images
  for i in range(9):
    # define subplot
    pyplot.subplot(330 + 1 + i)
    # plot raw pixel data
    pyplot.imshow(trainX[500+i])
  # show the figure
  pyplot.show()

explore_data()

"""**Function to load the data set and split into training and testing data sets**"""

def load_dataset():
	# load dataset
	(trainX, trainY), (testX, testY) = cifar10.load_data()
	# one hot encode target values
	trainY = to_categorical(trainY)
	testY = to_categorical(testY)
	return trainX, trainY, testX, testY

"""**This function will preprocess the images and normalize the pixel values**"""

def preprocess_pixel_values(train, test):
	train_norm = (train.astype('float32') / 255.0)
	test_norm = (test.astype('float32') / 255.0)
	return train_norm, test_norm

"""**This is the code for the model used to train**"""

def make_model():
  model = Sequential()
  model.add(Conv2D(64, (3, 3), activation='relu',input_shape=(32, 32, 3)))
  model.add(BatchNormalization())
  model.add(Conv2D(64, (2, 2), activation='relu',padding='same'))
  model.add(MaxPooling2D(2, 2))
  model.add(Dropout(0.1))

  model.add(BatchNormalization())
  model.add(Conv2D(64, (3, 3), activation='relu',padding='same'))
  model.add(MaxPooling2D(2, 2))
  model.add(Dropout(0.2))

  model.add(BatchNormalization())
  model.add(Conv2D(64, (2, 2), activation='relu',padding='same'))
  model.add(MaxPooling2D(2, 2))
  model.add(Dropout(0.1))

  model.add(Flatten())
  model.add(Dense(64, activation='relu'))
  model.add(BatchNormalization())
  model.add(Dropout(0.2))

  model.add(Dense(10, activation='softmax'))
  opt = RMSprop(learning_rate=0.0001, decay=1e-6)
  return model,opt

"""**Main function**"""

def main():
  explore_data()
  train_X,train_Y,test_X,test_Y = load_dataset()
  print("DATASET LOADING DONE")
  train_X,test_X = preprocess_pixel_values(train_X,test_X)
  print("PIXEL PROCESSING DONE")
  model,opt = make_model()
  print("MODEL OBTAINED")
  model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])
  print("MODEL COMPILED")
  history = model.fit(train_X, train_Y, epochs=50, batch_size=100, validation_data=(test_X, test_Y))
  print("MODEL FIT")
  evaluation,accuracy = model.evaluate(test_X,test_Y)
  print(accuracy)
  model.save('final_model.h5')
  model.summary()
  display_graph(history)
  evaluate_model(model,test_X,test_Y)

"""**Model Evaluation and printing test loss and accuracy**"""

def evaluate_model(model,test_X,test_Y):
  score = model.evaluate(test_X, test_Y)
  print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')

"""**Displays graphs for losses and accuracies**"""

def display_graph(history): 
  plt.style.use("ggplot")
  plt.figure()
  plt.plot(np.arange(0, 50), history.history["loss"], label="train_loss")
  plt.plot(np.arange(0, 50), history.history["val_loss"], label="val_loss")
  plt.title("Training Loss")
  plt.xlabel("Epoch")
  plt.ylabel("Loss")
  plt.legend(loc="lower left")
  plt.show()
  plt.plot(np.arange(0, 50), history.history["accuracy"], label="train_acc")
  plt.plot(np.arange(0, 50), history.history["val_accuracy"], label="val_acc")
  plt.title("Training Accuracy")
  plt.xlabel("Epoch")
  plt.ylabel("Accuracy")
  plt.legend(loc="lower left")
  plt.show()

"""**Calling the main function. Kindly run the previous cells before this. Use a GPU enabled runtime for optimal performance (Takes 9-10 minutes)**"""

main()